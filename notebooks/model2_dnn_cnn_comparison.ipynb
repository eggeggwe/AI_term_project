{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3803372",
   "metadata": {},
   "source": [
    "AI 期末作業 - DNN vs CNN 分類模型比較\n",
    "==================================\n",
    "此腳本將時間序列人流資料進行分類預測，\n",
    "同時使用 DNN 和 CNN 兩種模型進行訓練與比較。\n",
    "\n",
    "每個 ###### 註解區塊可作為 Jupyter Notebook 的獨立 cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76392c3",
   "metadata": {},
   "source": [
    "Cell 1: 匯入套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c9681f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 設定隨機種子以確保結果可重現\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a143456",
   "metadata": {},
   "source": [
    "Cell 2: 載入資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732d7e78",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/task1_dataset_kotae.csv\")\n",
    "print(f\"資料總筆數: {len(df)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badee966",
   "metadata": {},
   "source": [
    "Cell 3: 資料統計與分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a5cefd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"x 範圍: {df['x'].min()} ~ {df['x'].max()}\")\n",
    "print(f\"y 範圍: {df['y'].min()} ~ {df['y'].max()}\")\n",
    "print(f\"t 範圍: {df['t'].min()} ~ {df['t'].max()}\")\n",
    "\n",
    "# 計算各位置的人流統計\n",
    "count_table = df.value_counts(['x', 'y', 't', 'd']).reset_index(name='number of people')\n",
    "count_table_for_analyse = df.value_counts(['x', 'y']).reset_index(name='number of people')\n",
    "count_table_for_analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0873e42",
   "metadata": {},
   "source": [
    "Cell 4: 選擇前三大人流地點"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0345f062",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 找出人口數前三多的地點\n",
    "top_3_locations = count_table_for_analyse.nlargest(3, 'number of people')\n",
    "print(\"人口數前三多的地點 (x, y):\")\n",
    "print(top_3_locations)\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# 從 count_table 中篩選這三個地點的資料\n",
    "locations_to_find = top_3_locations[['x', 'y']]\n",
    "result_df = pd.merge(count_table, locations_to_find, on=['x', 'y'], how='inner')\n",
    "print(f\"篩選後資料筆數: {len(result_df)}\")\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d6770e",
   "metadata": {},
   "source": [
    "Cell 5: Reshape 資料 - 將 t 轉為小時"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5863aa69",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 1. 建立樞紐分析表\n",
    "pivot_df = result_df.pivot_table(\n",
    "    index=['x', 'y', 'd'], \n",
    "    columns='t', \n",
    "    values='number of people', \n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "# 2. 確保所有時間點 (0-47) 都存在\n",
    "pivot_df = pivot_df.reindex(columns=np.arange(48), fill_value=0)\n",
    "\n",
    "# 3. 將半小時資料合併為一小時 (Sum)\n",
    "data_hourly = pivot_df.T.groupby(lambda t: t // 2).sum().T\n",
    "\n",
    "print(\"資料轉換完成！\")\n",
    "print(f\"資料維度 (樣本數, 24小時): {data_hourly.shape}\")\n",
    "data_hourly.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43838062",
   "metadata": {},
   "source": [
    "Cell 6: 製作分類標籤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990a4740",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "X_list = []\n",
    "y_list = []\n",
    "\n",
    "# 製作早上的資料 (0-7時) - Label 0\n",
    "X_morning = data_hourly.loc[:, 0:7].values\n",
    "y_morning = np.zeros(len(X_morning))\n",
    "X_list.append(X_morning)\n",
    "y_list.append(y_morning)\n",
    "\n",
    "# 製作下午的資料 (8-15時) - Label 1\n",
    "X_afternoon = data_hourly.loc[:, 8:15].values\n",
    "y_afternoon = np.ones(len(X_afternoon))\n",
    "X_list.append(X_afternoon)\n",
    "y_list.append(y_afternoon)\n",
    "\n",
    "# 製作晚上的資料 (16-23時) - Label 2\n",
    "X_evening = data_hourly.loc[:, 16:23].values\n",
    "y_evening = np.full(len(X_evening), 2)\n",
    "X_list.append(X_evening)\n",
    "y_list.append(y_evening)\n",
    "\n",
    "# 合併所有資料\n",
    "X = np.concatenate(X_list, axis=0)\n",
    "y = np.concatenate(y_list, axis=0)\n",
    "\n",
    "print(f\"特徵資料 X 形狀: {X.shape} (樣本數, 8小時人流)\")\n",
    "print(f\"標籤資料 y 形狀: {y.shape} (對應的時段標籤)\")\n",
    "print(f\"類別分布: 早上={np.sum(y==0)}, 下午={np.sum(y==1)}, 晚上={np.sum(y==2)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847d45cd",
   "metadata": {},
   "source": [
    "Cell 7: 分割訓練集與測試集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f54a888",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 切分資料：80% 訓練, 20% 測試\n",
    "X_train_np, X_test_np, y_train_np, y_test_np = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "# 轉換為 PyTorch Tensor\n",
    "X_train = torch.FloatTensor(X_train_np)\n",
    "X_test = torch.FloatTensor(X_test_np)\n",
    "y_train = torch.LongTensor(y_train_np)\n",
    "y_test = torch.LongTensor(y_test_np)\n",
    "\n",
    "print(f\"訓練集 Tensor 形狀: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"測試集 Tensor 形狀: {X_test.shape}, {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae74ceb2",
   "metadata": {},
   "source": [
    "Cell 8: 定義 DNN 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfc1c33",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class DNNClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    深度神經網路 (DNN) 分類器\n",
    "    架構: 輸入(8) -> 隱藏層1(64) -> 隱藏層2(32) -> 輸出(3)\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size=8, hidden1=64, hidden2=32, num_classes=3, dropout=0.2):\n",
    "        super(DNNClassifier, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, hidden1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.layer2 = nn.Linear(hidden1, hidden2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.output = nn.Linear(hidden2, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "print(\"DNN 模型架構已定義\")\n",
    "dnn_model = DNNClassifier()\n",
    "print(dnn_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091ec435",
   "metadata": {},
   "source": [
    "Cell 9: 定義 CNN 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758259ef",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class CNNClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    卷積神經網路 (CNN) 分類器\n",
    "    使用 1D 卷積處理時間序列資料\n",
    "    架構: 輸入(1, 8) -> Conv1d -> Pool -> Conv1d -> FC -> 輸出(3)\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size=8, num_classes=3, dropout=0.2):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        \n",
    "        # 第一層卷積: 1 通道 -> 32 通道, kernel_size=3\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2)  # 8 -> 4\n",
    "        \n",
    "        # 第二層卷積: 32 通道 -> 64 通道, kernel_size=3\n",
    "        self.conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2)  # 4 -> 2\n",
    "        \n",
    "        # 全連接層\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(64 * 2, 32)  # 64 通道 * 2 長度\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(32, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 輸入 x 的形狀: (batch_size, 8)\n",
    "        # 需要轉換為 (batch_size, 1, 8) 以符合 Conv1d 的輸入要求\n",
    "        x = x.unsqueeze(1)  # (batch_size, 1, 8)\n",
    "        \n",
    "        # 第一層卷積\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)  # (batch_size, 32, 4)\n",
    "        \n",
    "        # 第二層卷積\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)  # (batch_size, 64, 2)\n",
    "        \n",
    "        # 全連接層\n",
    "        x = self.flatten(x)  # (batch_size, 128)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "print(\"CNN 模型架構已定義\")\n",
    "cnn_model = CNNClassifier()\n",
    "print(cnn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287333fb",
   "metadata": {},
   "source": [
    "Cell 10: 定義通用訓練函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b847a5a5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, X_train, y_train, X_test, y_test, \n",
    "                epochs=50, batch_size=16, learning_rate=0.001, model_name=\"Model\"):\n",
    "    \"\"\"\n",
    "    通用模型訓練函數\n",
    "    \n",
    "    Args:\n",
    "        model: PyTorch 模型\n",
    "        X_train, y_train: 訓練資料\n",
    "        X_test, y_test: 測試資料\n",
    "        epochs: 訓練輪數\n",
    "        batch_size: 批次大小\n",
    "        learning_rate: 學習率\n",
    "        model_name: 模型名稱（用於輸出）\n",
    "    \n",
    "    Returns:\n",
    "        history: 訓練歷史紀錄\n",
    "    \"\"\"\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    history = {\n",
    "        'accuracy': [], \n",
    "        'loss': [], \n",
    "        'val_accuracy': [], \n",
    "        'val_loss': []\n",
    "    }\n",
    "    \n",
    "    n_samples = X_train.shape[0]\n",
    "    \n",
    "    print(f\"\\n開始訓練 {model_name}...\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # --- 訓練階段 ---\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        correct_train = 0\n",
    "        \n",
    "        permutation = torch.randperm(n_samples)\n",
    "        \n",
    "        for i in range(0, n_samples, batch_size):\n",
    "            indices = permutation[i:i+batch_size]\n",
    "            batch_x, batch_y = X_train[indices], y_train[indices]\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item() * batch_x.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_train += (predicted == batch_y).sum().item()\n",
    "        \n",
    "        avg_train_loss = train_loss / n_samples\n",
    "        train_acc = correct_train / n_samples\n",
    "        \n",
    "        # --- 驗證階段 ---\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(X_test)\n",
    "            v_loss = criterion(val_outputs, y_test)\n",
    "            _, val_predicted = torch.max(val_outputs, 1)\n",
    "            val_acc = (val_predicted == y_test).sum().item() / len(y_test)\n",
    "            val_loss = v_loss.item()\n",
    "        \n",
    "        # 紀錄歷史數據\n",
    "        history['loss'].append(avg_train_loss)\n",
    "        history['accuracy'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_accuracy'].append(val_acc)\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], '\n",
    "                  f'Loss: {avg_train_loss:.4f}, Acc: {train_acc:.4f}, '\n",
    "                  f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "    \n",
    "    print(f\"{model_name} 訓練完成！\")\n",
    "    print(f\"最終訓練準確率: {history['accuracy'][-1]:.4f}\")\n",
    "    print(f\"最終驗證準確率: {history['val_accuracy'][-1]:.4f}\")\n",
    "    \n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18da273f",
   "metadata": {},
   "source": [
    "Cell 11: 訓練 DNN 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c43187",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 初始化 DNN 模型\n",
    "dnn_model = DNNClassifier()\n",
    "\n",
    "# 訓練 DNN\n",
    "dnn_history = train_model(\n",
    "    model=dnn_model,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    epochs=50,\n",
    "    batch_size=16,\n",
    "    learning_rate=0.001,\n",
    "    model_name=\"DNN\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f45bb67",
   "metadata": {},
   "source": [
    "Cell 12: 訓練 CNN 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3859a6b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 初始化 CNN 模型\n",
    "cnn_model = CNNClassifier()\n",
    "\n",
    "# 訓練 CNN\n",
    "cnn_history = train_model(\n",
    "    model=cnn_model,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    epochs=50,\n",
    "    batch_size=16,\n",
    "    learning_rate=0.001,\n",
    "    model_name=\"CNN\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe97307",
   "metadata": {},
   "source": [
    "Cell 13: 視覺化比較 DNN vs CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a58e3a7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# DNN 準確率\n",
    "axes[0, 0].plot(dnn_history['accuracy'], label='Train Accuracy', color='blue')\n",
    "axes[0, 0].plot(dnn_history['val_accuracy'], label='Val Accuracy', color='orange')\n",
    "axes[0, 0].set_title('DNN - Accuracy')\n",
    "axes[0, 0].set_xlabel('Epochs')\n",
    "axes[0, 0].set_ylabel('Accuracy')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True)\n",
    "\n",
    "# DNN Loss\n",
    "axes[0, 1].plot(dnn_history['loss'], label='Train Loss', color='blue')\n",
    "axes[0, 1].plot(dnn_history['val_loss'], label='Val Loss', color='orange')\n",
    "axes[0, 1].set_title('DNN - Loss')\n",
    "axes[0, 1].set_xlabel('Epochs')\n",
    "axes[0, 1].set_ylabel('Loss')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True)\n",
    "\n",
    "# CNN 準確率\n",
    "axes[1, 0].plot(cnn_history['accuracy'], label='Train Accuracy', color='green')\n",
    "axes[1, 0].plot(cnn_history['val_accuracy'], label='Val Accuracy', color='red')\n",
    "axes[1, 0].set_title('CNN - Accuracy')\n",
    "axes[1, 0].set_xlabel('Epochs')\n",
    "axes[1, 0].set_ylabel('Accuracy')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True)\n",
    "\n",
    "# CNN Loss\n",
    "axes[1, 1].plot(cnn_history['loss'], label='Train Loss', color='green')\n",
    "axes[1, 1].plot(cnn_history['val_loss'], label='Val Loss', color='red')\n",
    "axes[1, 1].set_title('CNN - Loss')\n",
    "axes[1, 1].set_xlabel('Epochs')\n",
    "axes[1, 1].set_ylabel('Loss')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('DNN vs CNN 訓練過程比較', fontsize=14, y=1.02)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7cfd59",
   "metadata": {},
   "source": [
    "Cell 14: DNN vs CNN 直接對比圖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ca787a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# 準確率對比\n",
    "axes[0].plot(dnn_history['val_accuracy'], label='DNN Val Accuracy', color='blue', linewidth=2)\n",
    "axes[0].plot(cnn_history['val_accuracy'], label='CNN Val Accuracy', color='green', linewidth=2)\n",
    "axes[0].set_title('DNN vs CNN - Validation Accuracy 對比')\n",
    "axes[0].set_xlabel('Epochs')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Loss 對比\n",
    "axes[1].plot(dnn_history['val_loss'], label='DNN Val Loss', color='blue', linewidth=2)\n",
    "axes[1].plot(cnn_history['val_loss'], label='CNN Val Loss', color='green', linewidth=2)\n",
    "axes[1].set_title('DNN vs CNN - Validation Loss 對比')\n",
    "axes[1].set_xlabel('Epochs')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6e8b02",
   "metadata": {},
   "source": [
    "Cell 15: 模型效能總結"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234d0341",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"模型效能總結\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "dnn_final_acc = dnn_history['val_accuracy'][-1]\n",
    "cnn_final_acc = cnn_history['val_accuracy'][-1]\n",
    "dnn_final_loss = dnn_history['val_loss'][-1]\n",
    "cnn_final_loss = cnn_history['val_loss'][-1]\n",
    "\n",
    "print(f\"\\n{'模型':<10} {'訓練準確率':<15} {'驗證準確率':<15} {'驗證 Loss':<15}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'DNN':<10} {dnn_history['accuracy'][-1]:<15.4f} {dnn_final_acc:<15.4f} {dnn_final_loss:<15.4f}\")\n",
    "print(f\"{'CNN':<10} {cnn_history['accuracy'][-1]:<15.4f} {cnn_final_acc:<15.4f} {cnn_final_loss:<15.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "if cnn_final_acc > dnn_final_acc:\n",
    "    print(f\"結論: CNN 模型表現較佳，驗證準確率高出 {(cnn_final_acc - dnn_final_acc)*100:.2f}%\")\n",
    "elif dnn_final_acc > cnn_final_acc:\n",
    "    print(f\"結論: DNN 模型表現較佳，驗證準確率高出 {(dnn_final_acc - cnn_final_acc)*100:.2f}%\")\n",
    "else:\n",
    "    print(\"結論: DNN 和 CNN 模型表現相當\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffc4e69",
   "metadata": {},
   "source": [
    "Cell 16: 儲存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a3a8cd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "save_dir = '../models'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "    print(f\"已建立資料夾: {save_dir}\")\n",
    "\n",
    "# 儲存 DNN 模型\n",
    "dnn_path = os.path.join(save_dir, 'dnn_time_classifier.pth')\n",
    "torch.save(dnn_model.state_dict(), dnn_path)\n",
    "print(f\"DNN 模型已儲存至: {dnn_path}\")\n",
    "\n",
    "# 儲存 CNN 模型\n",
    "cnn_path = os.path.join(save_dir, 'cnn_time_classifier.pth')\n",
    "torch.save(cnn_model.state_dict(), cnn_path)\n",
    "print(f\"CNN 模型已儲存至: {cnn_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d974f7",
   "metadata": {},
   "source": [
    "Cell 17: 載入模型並進行推論測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802c2c5e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 載入 DNN 模型\n",
    "loaded_dnn = DNNClassifier()\n",
    "loaded_dnn.load_state_dict(torch.load(dnn_path, weights_only=True))\n",
    "loaded_dnn.eval()\n",
    "\n",
    "# 載入 CNN 模型\n",
    "loaded_cnn = CNNClassifier()\n",
    "loaded_cnn.load_state_dict(torch.load(cnn_path, weights_only=True))\n",
    "loaded_cnn.eval()\n",
    "\n",
    "# 進行推論測試\n",
    "with torch.no_grad():\n",
    "    # 使用測試集進行推論\n",
    "    dnn_preds = loaded_dnn(X_test)\n",
    "    cnn_preds = loaded_cnn(X_test)\n",
    "    \n",
    "    _, dnn_predicted = torch.max(dnn_preds, 1)\n",
    "    _, cnn_predicted = torch.max(cnn_preds, 1)\n",
    "    \n",
    "    dnn_test_acc = (dnn_predicted == y_test).sum().item() / len(y_test)\n",
    "    cnn_test_acc = (cnn_predicted == y_test).sum().item() / len(y_test)\n",
    "\n",
    "print(\"模型載入成功！\")\n",
    "print(f\"DNN 測試準確率: {dnn_test_acc:.4f}\")\n",
    "print(f\"CNN 測試準確率: {cnn_test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a27d15",
   "metadata": {},
   "source": [
    "Cell 18: (額外) 不同參數實驗 - 層數/神經元數比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30a7e3f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 這個 cell 可以用於參數討論，探討不同模型架構的影響\n",
    "\n",
    "def experiment_dnn_architectures(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    探討不同 DNN 架構對模型效能的影響\n",
    "    \"\"\"\n",
    "    architectures = [\n",
    "        {\"hidden1\": 32, \"hidden2\": 16, \"name\": \"DNN (32-16)\"},\n",
    "        {\"hidden1\": 64, \"hidden2\": 32, \"name\": \"DNN (64-32)\"},\n",
    "        {\"hidden1\": 128, \"hidden2\": 64, \"name\": \"DNN (128-64)\"},\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for arch in architectures:\n",
    "        print(f\"\\n訓練 {arch['name']}...\")\n",
    "        model = DNNClassifier(hidden1=arch['hidden1'], hidden2=arch['hidden2'])\n",
    "        \n",
    "        history = train_model(\n",
    "            model=model,\n",
    "            X_train=X_train,\n",
    "            y_train=y_train,\n",
    "            X_test=X_test,\n",
    "            y_test=y_test,\n",
    "            epochs=50,\n",
    "            batch_size=16,\n",
    "            learning_rate=0.001,\n",
    "            model_name=arch['name']\n",
    "        )\n",
    "        \n",
    "        results.append({\n",
    "            'name': arch['name'],\n",
    "            'final_val_acc': history['val_accuracy'][-1],\n",
    "            'final_val_loss': history['val_loss'][-1],\n",
    "            'history': history\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# 執行參數實驗\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"開始進行 DNN 不同架構參數實驗\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "arch_results = experiment_dnn_architectures(X_train, y_train, X_test, y_test)\n",
    "\n",
    "# 繪製實驗結果\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "for result in arch_results:\n",
    "    axes[0].plot(result['history']['val_accuracy'], label=result['name'], linewidth=2)\n",
    "    axes[1].plot(result['history']['val_loss'], label=result['name'], linewidth=2)\n",
    "\n",
    "axes[0].set_title('不同 DNN 架構 - Validation Accuracy 比較')\n",
    "axes[0].set_xlabel('Epochs')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "axes[1].set_title('不同 DNN 架構 - Validation Loss 比較')\n",
    "axes[1].set_xlabel('Epochs')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 輸出實驗結果總結\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"不同架構參數實驗結果總結\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\n{'架構':<20} {'驗證準確率':<15} {'驗證 Loss':<15}\")\n",
    "print(\"-\" * 50)\n",
    "for result in arch_results:\n",
    "    print(f\"{result['name']:<20} {result['final_val_acc']:<15.4f} {result['final_val_loss']:<15.4f}\")\n",
    "\n",
    "best_arch = max(arch_results, key=lambda x: x['final_val_acc'])\n",
    "print(f\"\\n最佳架構: {best_arch['name']} (驗證準確率: {best_arch['final_val_acc']:.4f})\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
