{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4bf237",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import os\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b2f9e9",
   "metadata": {},
   "source": [
    "1. ÂèÉÊï∏Ë®≠ÂÆö (Configuration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dd5f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data/task1_dataset_kotae.csv\"\n",
    "MODEL_SAVE_DIR = \"../models\"\n",
    "MODEL_SAVE_PATH = f\"{MODEL_SAVE_DIR}/seq2seq_multivariate_timeperiod.pth\"\n",
    "SCALER_SAVE_PATH = f\"{MODEL_SAVE_DIR}/scaler_multivariate_timeperiod.pkl\"\n",
    "LOG_SAVE_PATH = f\"{MODEL_SAVE_DIR}/eval_log_multivariate_timeperiod.txt\"\n",
    "\n",
    "# Ê®°ÂûãË∂ÖÂèÉÊï∏ÔºàËàá model1, multivariate Áõ∏ÂêåÔºâ\n",
    "INPUT_SEQ_LEN = 144   # Ëº∏ÂÖ•ÈÅéÂéª 72 Â∞èÊôÇ\n",
    "OUTPUT_SEQ_LEN = 48   # È†êÊ∏¨Êú™‰æÜ 24 Â∞èÊôÇ\n",
    "BATCH_SIZE = 512\n",
    "HIDDEN_SIZE = 256\n",
    "NUM_LAYERS = 4\n",
    "EPOCHS = 200\n",
    "PATIENCE = 20  # Early Stopping ËÄêÂøÉÂÄº\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# ÁâπÂæµÁ∂≠Â∫¶Ë®≠ÂÆö\n",
    "# [‰∫∫Êï∏, is_weekend, time_period_0, time_period_1, time_period_2, time_period_3]\n",
    "# ÊôÇÊÆµ‰ΩøÁî® One-Hot Á∑®Á¢º (4Á∂≠)ÔºåÊâÄ‰ª•Á∏ΩÂÖ± 1 + 1 + 4 = 6 Á∂≠\n",
    "INPUT_SIZE = 6        \n",
    "OUTPUT_SIZE = 1       # [‰∫∫Êï∏]\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "os.makedirs(MODEL_SAVE_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b77f84",
   "metadata": {},
   "source": [
    "2. Ë≥áÊñôËôïÁêÜËàáÊ®ôÁ±§ÁîüÊàê (Data Processing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f91fdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_period(t):\n",
    "    \"\"\"\n",
    "    Ê†πÊìöÊôÇÈñìÈªû t (0-47) ÂàÜÈ°ûÁÇ∫‰∏çÂêåÊôÇÊÆµ\n",
    "    ÊØèÂÄã t ‰ª£Ë°® 30 ÂàÜÈêòÔºåÊâÄ‰ª•Ôºö\n",
    "    - t=0 ‰ª£Ë°® 00:00, t=1 ‰ª£Ë°® 00:30, ...\n",
    "    - t=16 ‰ª£Ë°® 08:00, t=24 ‰ª£Ë°® 12:00, ...\n",
    "    \n",
    "    ÊôÇÊÆµÂàÜÈ°ûÔºö\n",
    "    - 0: Ê∑±Â§ú (00:00 - 06:00) -> t: 0-11\n",
    "    - 1: Êó©‰∏ä (06:00 - 12:00) -> t: 12-23\n",
    "    - 2: ‰∏ãÂçà (12:00 - 18:00) -> t: 24-35\n",
    "    - 3: Êôö‰∏ä (18:00 - 24:00) -> t: 36-47\n",
    "    \"\"\"\n",
    "    if t < 12:\n",
    "        return 0  # Ê∑±Â§ú\n",
    "    elif t < 24:\n",
    "        return 1  # Êó©‰∏ä\n",
    "    elif t < 36:\n",
    "        return 2  # ‰∏ãÂçà\n",
    "    else:\n",
    "        return 3  # Êôö‰∏ä\n",
    "\n",
    "def load_and_preprocess_data(path):\n",
    "    print(\"Loading raw data...\")\n",
    "    raw_df = pd.read_csv(path)\n",
    "    \n",
    "    # --- ‰øÆÊ≠£ÈªûÔºöÂÖàÂ∞áÂéüÂßãË≥áÊñôËÅöÂêàÁÆóÂá∫‰∫∫Êï∏ ---\n",
    "    print(\"Aggregating data to calculate 'number of people'...\")\n",
    "    df = raw_df.groupby(['d', 't', 'x', 'y']).size().reset_index(name='number of people')\n",
    "    \n",
    "    print(f\"Aggregated data shape: {df.shape}\")\n",
    "    \n",
    "    # --- A. Ëá™ÂãïÁîüÊàê Weekend Ê®ôÁ±§ (K-Means) ---\n",
    "    print(\"Generating 'is_weekend' labels using K-Means...\")\n",
    "    \n",
    "    # ÈÅ∏ÊìáÁ∏Ω‰∫∫Êï∏ÊúÄÂ§öÁöÑÁ∂≤Ê†º‰ΩúÁÇ∫Âü∫Ê∫ñ\n",
    "    top_grid_idx = df.groupby(['x', 'y'])['number of people'].sum().idxmax()\n",
    "    print(f\"Base grid for clustering: {top_grid_idx}\")\n",
    "    \n",
    "    base_df = df[(df['x'] == top_grid_idx[0]) & (df['y'] == top_grid_idx[1])].copy()\n",
    "    \n",
    "    # Ê≥®ÊÑèÔºöÁÇ∫‰∫ÜËàá model1.ipynb Â∞çÈΩäÊØîËºÉÔºåÊ≠§ËôïÁßªÈô§ÊôÇÈñìË£úÈõ∂ËôïÁêÜ\n",
    "    # Áõ¥Êé•‰ΩøÁî®ÂéüÂßãË≥áÊñôÈÄ≤Ë°åÂæåÁ∫åËôïÁêÜ\n",
    "\n",
    "    # ËΩâÊàêÁü©Èô£: Index=Â§©Êï∏, Columns=ÊôÇÈñìÈªû\n",
    "    pivot_matrix = base_df.pivot(index='d', columns='t', values='number of people').fillna(0)\n",
    "    \n",
    "    # K-Means ÂàÜÁæ§\n",
    "    kmeans = KMeans(n_clusters=2, random_state=42, n_init=10).fit(pivot_matrix)\n",
    "    labels = kmeans.labels_\n",
    "    \n",
    "    # Âà§Êñ∑Âì™‰∏ÄÁæ§ÊòØÈÄ±Êú´\n",
    "    c0_idx = np.where(labels == 0)[0]\n",
    "    c1_idx = np.where(labels == 1)[0]\n",
    "    \n",
    "    # ÊØîËºÉ t=16 (Êó©‰∏ä8Èªû) ÁöÑÂπ≥Âùá‰∫∫ÊµÅ\n",
    "    if len(c0_idx) > 0 and len(c1_idx) > 0:\n",
    "        avg_flow_0 = pivot_matrix.iloc[c0_idx, 16].mean()\n",
    "        avg_flow_1 = pivot_matrix.iloc[c1_idx, 16].mean()\n",
    "        weekend_label_cluster = 0 if avg_flow_0 < avg_flow_1 else 1\n",
    "    else:\n",
    "        # Ê•µÁ´ØÊÉÖÊ≥ÅËôïÁêÜ\n",
    "        weekend_label_cluster = 1 if len(c0_idx) < len(c1_idx) else 0\n",
    "\n",
    "    # Âª∫Á´ãÊò†Â∞ÑË°®\n",
    "    day_is_weekend = [1 if l == weekend_label_cluster else 0 for l in labels]\n",
    "    label_map = pd.DataFrame({'d': pivot_matrix.index, 'is_weekend': day_is_weekend})\n",
    "    \n",
    "    print(f\"Weekday count: {len(label_map[label_map['is_weekend']==0])}\")\n",
    "    print(f\"Weekend count: {len(label_map[label_map['is_weekend']==1])}\")\n",
    "    \n",
    "    # --- B. ÁîüÊàêÊôÇÊÆµÊ®ôÁ±§ (One-Hot Á∑®Á¢º) ---\n",
    "    print(\"Generating 'time_period' labels with One-Hot encoding...\")\n",
    "    df['time_period'] = df['t'].apply(get_time_period)\n",
    "    \n",
    "    # One-Hot Á∑®Á¢ºÔºöÂª∫Á´ã 4 ÂÄãÊ¨Ñ‰Ωç\n",
    "    df['time_period_0'] = (df['time_period'] == 0).astype(float)  # Ê∑±Â§ú\n",
    "    df['time_period_1'] = (df['time_period'] == 1).astype(float)  # Êó©‰∏ä\n",
    "    df['time_period_2'] = (df['time_period'] == 2).astype(float)  # ‰∏ãÂçà\n",
    "    df['time_period_3'] = (df['time_period'] == 3).astype(float)  # Êôö‰∏ä\n",
    "    \n",
    "    period_counts = df['time_period'].value_counts().sort_index()\n",
    "    print(f\"ÊôÇÊÆµÂàÜÂ∏É: Ê∑±Â§ú(0)={period_counts.get(0, 0)}, Êó©‰∏ä(1)={period_counts.get(1, 0)}, ‰∏ãÂçà(2)={period_counts.get(2, 0)}, Êôö‰∏ä(3)={period_counts.get(3, 0)}\")\n",
    "    print(\"‰ΩøÁî® One-Hot Á∑®Á¢ºË°®Á§∫ÊôÇÊÆµÁâπÂæµ (4Á∂≠)\")\n",
    "    \n",
    "    # --- C. ÁØ©ÈÅ∏Ââç‰∏âÂ§ßÁÜ±Èªû‰∏¶Âêà‰ΩµÊ®ôÁ±§ ---\n",
    "    print(\"Selecting Top 3 locations...\")\n",
    "    top_3 = df.groupby(['x', 'y'])['number of people'].sum().nlargest(3).reset_index()[['x', 'y']]\n",
    "    \n",
    "    # Âè™‰øùÁïôÈÄô‰∏âÂÄãÂú∞ÈªûÁöÑË≥áÊñô\n",
    "    result_df = pd.merge(df, top_3, on=['x', 'y'], how='inner')\n",
    "    \n",
    "    # Âêà‰Ωµ K-Means Áî¢ÁîüÁöÑÊ®ôÁ±§\n",
    "    result_df = pd.merge(result_df, label_map, on='d', how='left')\n",
    "    \n",
    "    # --- D. Ê®ôÊ∫ñÂåñ (Normalization) ---\n",
    "    scaler = MinMaxScaler()\n",
    "    result_df['number_scaled'] = scaler.fit_transform(result_df[['number of people']])\n",
    "    \n",
    "    return result_df, scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629f140d",
   "metadata": {},
   "source": [
    "3. Ëá™ÂÆöÁæ© Dataset (Multivariate with One-Hot Time Period)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6395dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridTimeSeriesDataset(Dataset):\n",
    "    def __init__(self, df, group_by_cols, target_col, input_seq_len, output_seq_len):\n",
    "        \"\"\"\n",
    "        ‰ΩøÁî® One-Hot Á∑®Á¢ºÁöÑÊôÇÊÆµÁâπÂæµ\n",
    "        Ëº∏ÂÖ•ÁâπÂæµ: [‰∫∫Êï∏, is_weekend, time_period_0, time_period_1, time_period_2, time_period_3]\n",
    "        \"\"\"\n",
    "        self.sequences = []\n",
    "        \n",
    "        grouped = df.groupby(group_by_cols)\n",
    "        \n",
    "        for _, group_df in grouped:\n",
    "            # Ê≠£Á¢∫ÁöÑÊéíÂ∫èÊñπÂºèÔºöÊåâ ['d', 't'] ÊéíÂ∫è\n",
    "            group_df = group_df.sort_values(['d', 't'])\n",
    "            \n",
    "            target_vals = group_df[target_col].values\n",
    "            is_weekend_vals = group_df['is_weekend'].values\n",
    "            tp0_vals = group_df['time_period_0'].values\n",
    "            tp1_vals = group_df['time_period_1'].values\n",
    "            tp2_vals = group_df['time_period_2'].values\n",
    "            tp3_vals = group_df['time_period_3'].values\n",
    "            \n",
    "            total_len = len(target_vals)\n",
    "            \n",
    "            # ÊªëÂãïË¶ñÁ™óÁîüÊàêÂ∫èÂàó\n",
    "            for i in range(total_len - input_seq_len - output_seq_len + 1):\n",
    "                in_target = target_vals[i : i + input_seq_len]\n",
    "                in_weekend = is_weekend_vals[i : i + input_seq_len]\n",
    "                in_tp0 = tp0_vals[i : i + input_seq_len]\n",
    "                in_tp1 = tp1_vals[i : i + input_seq_len]\n",
    "                in_tp2 = tp2_vals[i : i + input_seq_len]\n",
    "                in_tp3 = tp3_vals[i : i + input_seq_len]\n",
    "                \n",
    "                # Stack: (Seq_Len, 6) - ‰∫∫Êï∏ + is_weekend + 4ÂÄã One-Hot ÊôÇÊÆµ\n",
    "                input_seq = np.stack((in_target, in_weekend, in_tp0, in_tp1, in_tp2, in_tp3), axis=1)\n",
    "                \n",
    "                # Output: (Output_Len)\n",
    "                output_seq = target_vals[i + input_seq_len : i + input_seq_len + output_seq_len]\n",
    "                \n",
    "                self.sequences.append((input_seq, output_seq))\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        input_seq, output_seq = self.sequences[idx]\n",
    "        return torch.FloatTensor(input_seq), torch.FloatTensor(output_seq).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f3a1a0",
   "metadata": {},
   "source": [
    " 4. Ê®°ÂûãÊû∂Êßã (Seq2Seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75004acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, (hidden, cell) = self.lstm(x)\n",
    "        return hidden, cell\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_size, hidden_size, num_layers):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.lstm = nn.LSTM(output_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, hidden, cell):\n",
    "        output, (hidden, cell) = self.lstm(x, (hidden, cell))\n",
    "        prediction = self.fc(output)\n",
    "        return prediction, hidden, cell\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, target_len, device):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.target_len = target_len\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, source):\n",
    "        batch_size = source.shape[0]\n",
    "        hidden, cell = self.encoder(source)\n",
    "        \n",
    "        # Decoder ÂàùÂßãËº∏ÂÖ•Ë®≠ÁÇ∫ 0\n",
    "        decoder_input = torch.zeros(batch_size, 1, 1).to(self.device)\n",
    "        \n",
    "        outputs = []\n",
    "        for _ in range(self.target_len):\n",
    "            prediction, hidden, cell = self.decoder(decoder_input, hidden, cell)\n",
    "            outputs.append(prediction)\n",
    "            decoder_input = prediction \n",
    "            \n",
    "        outputs = torch.cat(outputs, dim=1) \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418f1735",
   "metadata": {},
   "source": [
    "5. ‰∏ªÂü∑Ë°åÊµÅÁ®ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad7810e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # --- Step 1: Ê∫ñÂÇôË≥áÊñô ---\n",
    "    df, scaler = load_and_preprocess_data(DATA_PATH)\n",
    "    \n",
    "    # --- Âõ∫ÂÆöÂàáÂàÜÔºö40 Â§©Ë®ìÁ∑¥Ôºå10 Â§©È©óË≠âÔºå25 Â§©Ê∏¨Ë©¶ ---\n",
    "    TRAIN_DAYS = 40\n",
    "    VAL_DAYS = 10\n",
    "    TEST_DAYS = 25\n",
    "    TOTAL_DAYS = 75\n",
    "    \n",
    "    # ÈáçÊñ∞Âª∫Á´ã DatasetÔºöÂàÜÂà•ÁÇ∫Ë®ìÁ∑¥ÈõÜ„ÄÅÈ©óË≠âÈõÜÂíåÊ∏¨Ë©¶ÈõÜ\n",
    "    train_df = df[df['d'] < TRAIN_DAYS]\n",
    "    val_df = df[(df['d'] >= TRAIN_DAYS) & (df['d'] < TRAIN_DAYS + VAL_DAYS)]\n",
    "    test_df = df[df['d'] >= TRAIN_DAYS + VAL_DAYS]\n",
    "    \n",
    "    print(f\"Ë®ìÁ∑¥ÈõÜÂ§©Êï∏: 0 ~ {TRAIN_DAYS-1} (ÂÖ± {TRAIN_DAYS} Â§©)\")\n",
    "    print(f\"È©óË≠âÈõÜÂ§©Êï∏: {TRAIN_DAYS} ~ {TRAIN_DAYS+VAL_DAYS-1} (ÂÖ± {VAL_DAYS} Â§©)\")\n",
    "    print(f\"Ê∏¨Ë©¶ÈõÜÂ§©Êï∏: {TRAIN_DAYS+VAL_DAYS} ~ {TOTAL_DAYS-1} (ÂÖ± {TEST_DAYS} Â§©)\")\n",
    "    \n",
    "    print(\"Creating dataset with One-Hot time period features...\")\n",
    "    train_dataset = GridTimeSeriesDataset(\n",
    "        train_df, \n",
    "        group_by_cols=['x', 'y'],\n",
    "        target_col='number_scaled',\n",
    "        input_seq_len=INPUT_SEQ_LEN,\n",
    "        output_seq_len=OUTPUT_SEQ_LEN\n",
    "    )\n",
    "    \n",
    "    val_dataset = GridTimeSeriesDataset(\n",
    "        val_df, \n",
    "        group_by_cols=['x', 'y'],\n",
    "        target_col='number_scaled',\n",
    "        input_seq_len=INPUT_SEQ_LEN,\n",
    "        output_seq_len=OUTPUT_SEQ_LEN\n",
    "    )\n",
    "    \n",
    "    test_dataset = GridTimeSeriesDataset(\n",
    "        test_df, \n",
    "        group_by_cols=['x', 'y'],\n",
    "        target_col='number_scaled',\n",
    "        input_seq_len=INPUT_SEQ_LEN,\n",
    "        output_seq_len=OUTPUT_SEQ_LEN\n",
    "    )\n",
    "    \n",
    "    if len(train_dataset) == 0:\n",
    "        print(\"Error: Train dataset is empty. Please check input sequence length and data continuity.\")\n",
    "        exit()\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    print(f\"Training samples: {len(train_dataset)}\")\n",
    "    print(f\"Validation samples: {len(val_dataset)}\")\n",
    "    print(f\"Testing samples: {len(test_dataset)}\")\n",
    "    \n",
    "    # --- Step 2: Âª∫Á´ãÊ®°Âûã ---\n",
    "    encoder = Encoder(INPUT_SIZE, HIDDEN_SIZE, NUM_LAYERS).to(DEVICE)\n",
    "    decoder = Decoder(OUTPUT_SIZE, HIDDEN_SIZE, NUM_LAYERS).to(DEVICE)\n",
    "    model = Seq2Seq(encoder, decoder, OUTPUT_SEQ_LEN, DEVICE).to(DEVICE)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    # --- Step 3: Ë®ìÁ∑¥Ëø¥Âúà (Âê´ Early Stopping) ---\n",
    "    print(\"Starting training...\")\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        \n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(x)\n",
    "            loss = criterion(output, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_train_loss += loss.item()\n",
    "            \n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        \n",
    "        # È©óË≠âÈöéÊÆµÔºö‰ΩøÁî®È©óË≠âÈõÜË®àÁÆó validation loss\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "                output = model(x)\n",
    "                val_loss = criterion(output, y)\n",
    "                total_val_loss += val_loss.item()\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS} | Train Loss: {avg_train_loss:.6f} | Val Loss: {avg_val_loss:.6f}\")\n",
    "        \n",
    "        # Early Stopping Ê™¢Êü•\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            print(f\"  ‚úì Best model updated (Val Loss: {best_val_loss:.6f})\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"  No improvement ({patience_counter}/{PATIENCE})\")\n",
    "            \n",
    "        if patience_counter >= PATIENCE:\n",
    "            print(f\"\\nEarly stopping triggered at epoch {epoch+1}!\")\n",
    "            break\n",
    "    \n",
    "    # ËºâÂÖ•ÊúÄ‰Ω≥Ê®°Âûã‰∏¶ÂÑ≤Â≠ò\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "    \n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'hyperparameters': {\n",
    "            'input_size': INPUT_SIZE,\n",
    "            'hidden_size': HIDDEN_SIZE,\n",
    "            'num_layers': NUM_LAYERS,\n",
    "            'input_seq_len': INPUT_SEQ_LEN,\n",
    "            'output_seq_len': OUTPUT_SEQ_LEN\n",
    "        }\n",
    "    }, MODEL_SAVE_PATH)\n",
    "            \n",
    "    print(f\"\\nTraining complete. Best model saved to {MODEL_SAVE_PATH}\")\n",
    "    joblib.dump(scaler, SCALER_SAVE_PATH)\n",
    "    \n",
    "    # --- Step 4: Ë©ï‰º∞Ê®°ÂûãÔºà‰ΩøÁî®Ê∏¨Ë©¶ÈõÜÔºâ---\n",
    "    print(\"\\n--- Ê®°ÂûãË©ï‰º∞ ---\")\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x = x.to(DEVICE)\n",
    "            output = model(x)\n",
    "            all_preds.append(output.cpu().numpy())\n",
    "            all_targets.append(y.numpy())\n",
    "    \n",
    "    preds = np.concatenate(all_preds, axis=0).reshape(-1, 1)\n",
    "    targets = np.concatenate(all_targets, axis=0).reshape(-1, 1)\n",
    "    \n",
    "    preds_original = scaler.inverse_transform(preds).flatten()\n",
    "    targets_original = scaler.inverse_transform(targets).flatten()\n",
    "    \n",
    "    mse = mean_squared_error(targets_original, preds_original)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(targets_original, preds_original)\n",
    "    \n",
    "    print(f\"üìà Ê®°ÂûãË©ï‰º∞ÁµêÊûú (Ê∏¨Ë©¶ÈõÜ):\")\n",
    "    print(f\"   MSE: {mse:.4f}\")\n",
    "    print(f\"   RMSE: {rmse:.4f}\")\n",
    "    print(f\"   MAE: {mae:.4f}\")\n",
    "    \n",
    "    # ÂÑ≤Â≠òË©ï‰º∞ÁµêÊûúÂà∞ log Ê™î\n",
    "    with open(LOG_SAVE_PATH, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"=\" * 50 + \"\\n\")\n",
    "        f.write(\"Ê®°Âûã: Multivariate + Time Period Seq2Seq (One-Hot)\\n\")\n",
    "        f.write(\"=\" * 50 + \"\\n\")\n",
    "        f.write(f\"Ëº∏ÂÖ•ÁâπÂæµ: [‰∫∫Êï∏, is_weekend, ÊôÇÊÆµ One-Hot (4Á∂≠)]\\n\")\n",
    "        f.write(f\"Ëº∏ÂÖ•ÁâπÂæµÊï∏: {INPUT_SIZE}\\n\")\n",
    "        f.write(f\"Ë®ìÁ∑¥ÈõÜ: Ââç 50 Â§© (Ê®£Êú¨Êï∏: {len(train_dataset)})\\n\")\n",
    "        f.write(f\"Ê∏¨Ë©¶ÈõÜ: Âæå 25 Â§© (Ê®£Êú¨Êï∏: {len(test_dataset)})\\n\")\n",
    "        f.write(\"\\n--- Ê∏¨Ë©¶ÈõÜË©ï‰º∞ÁµêÊûú ---\\n\")\n",
    "        f.write(f\"MSE:  {mse:.4f}\\n\")\n",
    "        f.write(f\"RMSE: {rmse:.4f}\\n\")\n",
    "        f.write(f\"MAE:  {mae:.4f}\\n\")\n",
    "        f.write(\"=\" * 50 + \"\\n\")\n",
    "    print(f\"üìù Ë©ï‰º∞ÁµêÊûúÂ∑≤ÂÑ≤Â≠òËá≥ {LOG_SAVE_PATH}\")\n",
    "    \n",
    "    # --- Step 5: Áï´ÂúñÔºà‰ΩøÁî®Ê∏¨Ë©¶ÈõÜÔºâ---\n",
    "    model.eval()\n",
    "    \n",
    "    # Êô∫ÊÖßÊêúÂ∞ãÔºöÂú®Ê∏¨Ë©¶ÈõÜ‰∏≠ÊêúÂ∞ã‰∫∫ÊµÅÊ≥¢ÂãïÊòéÈ°ØÁöÑÊ®£Êú¨\n",
    "    total_len = len(test_dataset)\n",
    "    print(f\"Ê∏¨Ë©¶ÈõÜÁ∏ΩÊï∏: {total_len}\")\n",
    "    \n",
    "    # ÊêúÂ∞ãÁÜ±ÈñÄÊôÇÊÆµ (High-traffic sample)\n",
    "    target_sample_idx = 0\n",
    "    found = False\n",
    "    \n",
    "    print(\"Ê≠£Âú®ÊêúÂ∞ã‰∫∫ÊµÅÊ≥¢ÂãïÊòéÈ°ØÁöÑÊ®£Êú¨ (Max > 80)...\")\n",
    "    \n",
    "    for i in range(total_len):\n",
    "        _, target_tensor = test_dataset[i]\n",
    "        # Âè™Âèñ‰∫∫Êï∏ÈÉ®ÂàÜÔºàÁ¨¨‰∏ÄÂÄãÁâπÂæµÔºâÈÄ≤Ë°åÂèçÊ®ôÊ∫ñÂåñ\n",
    "        temp_val = scaler.inverse_transform(target_tensor.numpy().reshape(-1, 1))\n",
    "        \n",
    "        if temp_val.max() > 80:\n",
    "            target_sample_idx = i\n",
    "            print(f\"‚úÖ ÊâæÂà∞ÁõÆÊ®ôÊ®£Êú¨ Index: {i} (ÊúÄÂ§ß‰∫∫ÊµÅ: {temp_val.max():.2f})\")\n",
    "            found = True\n",
    "            break\n",
    "    \n",
    "    if not found:\n",
    "        print(\"‚ö†Ô∏è Êú™ÊâæÂà∞ > 80 ÁöÑÊ®£Êú¨ÔºåÂ∞á‰ΩøÁî®Ê∏¨Ë©¶ÈõÜÁöÑÁ¨¨‰∏ÄÁ≠ÜË≥áÊñôÁπ™Âúñ„ÄÇ\")\n",
    "    \n",
    "    # ÂèñÂæóÊ®£Êú¨ÈÄ≤Ë°åÈ†êÊ∏¨\n",
    "    sample_input, sample_target = test_dataset[target_sample_idx]\n",
    "    sample_input = sample_input.unsqueeze(0).to(DEVICE)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        prediction = model(sample_input).cpu().numpy().reshape(-1, 1)\n",
    "        target = sample_target.numpy().reshape(-1, 1)\n",
    "        \n",
    "    pred_orig = scaler.inverse_transform(prediction)\n",
    "    target_orig = scaler.inverse_transform(target)\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(target_orig, label='Actual (Ground Truth)', linewidth=2)\n",
    "    plt.plot(pred_orig, label='Predicted (Multivariate + Time Period One-Hot)', linestyle='--', color='orange', linewidth=2)\n",
    "    plt.title(f\"Multivariate + Time Period (One-Hot) Seq2Seq Prediction (Sample Index: {target_sample_idx})\")\n",
    "    plt.xlabel(\"Time Steps (Next 24 Hours)\")\n",
    "    plt.ylabel(\"Number of People\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.savefig(f\"{MODEL_SAVE_DIR}/prediction_result_multivariate_timeperiod.png\")\n",
    "    plt.show()\n",
    "    print(f\"Result plot saved to {MODEL_SAVE_DIR}/prediction_result_multivariate_timeperiod.png\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
